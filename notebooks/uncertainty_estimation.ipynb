{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from uncertaintylearning.utils import (FixedKernelDensityEstimator, CVKernelDensityEstimator,\n",
    "                                       create_network, create_optimizer, create_multiplicative_scheduler)\n",
    "from uncertaintylearning.models import EpistemicPredictor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(x, noise=0.1):\n",
    "    # returns sin(2pi x) + epsilon with epsilon ~ N(0, 0.1)\n",
    "    with torch.no_grad():\n",
    "        m = torch.distributions.Normal(torch.tensor([0.0]), torch.tensor([1]))\n",
    "        m = m.sample((x.size(0),))\n",
    "        return (2 * np.pi * x).sin() + noise * m\n",
    "\n",
    "def generate_data(n=1024, sep=1):\n",
    "    # generate data from U([0, 1/2] union U([1/2 + sep, 1 + sep]))\n",
    "    # sep needs to be < 1.5\n",
    "    with torch.no_grad():\n",
    "        x = torch.zeros(n // 2, 1).uniform_(0, 0.5)\n",
    "        x = torch.cat((x, torch.zeros(n // 2, 1).uniform_(0.5 + sep, 1 + sep)), 0)\n",
    "        x_test = torch.linspace(-0.5, 2.5, 512).view(-1, 1)\n",
    "        ood_x = torch.FloatTensor(512, 1).uniform_(-0.5, 2.5)\n",
    "        y = oracle(x)\n",
    "        y2 = oracle(x)\n",
    "        ood_y = oracle(ood_x)\n",
    "        y_test_true = oracle(x_test, noise=0)\n",
    "        return x, y, y2, x_test, y_test_true, ood_x, ood_y\n",
    "\n",
    "x, y, y2, x_test, y_test, ood_x, ood_y = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_estimator = CVKernelDensityEstimator()\n",
    "additional_data = {'train_Y_2': y2,\n",
    "                  'ood_X': ood_x,\n",
    "                  'ood_Y': ood_y}\n",
    "networks = {'a_predictor': create_network(1, 1, 32, 'tanh', True),\n",
    "            'e_predictor': create_network(2, 1, 32, 'relu', True),\n",
    "            'f_predictor': create_network(1, 1, 64, 'relu', False)\n",
    "            }\n",
    "\n",
    "optimizers = {'a_optimizer': create_optimizer(networks['a_predictor'], 1e-2),\n",
    "              'e_optimizer': create_optimizer(networks['e_predictor'], 3e-3),\n",
    "              'f_optimizer': create_optimizer(networks['f_predictor'], 1e-3)\n",
    "              }\n",
    "schedulers = {'e_scheduler': create_multiplicative_scheduler(optimizers['e_optimizer'],\n",
    "                                                            lr_schedule=0.999)\n",
    "}\n",
    "model = EpistemicPredictor(train_X=x,\n",
    "                           train_Y=y,\n",
    "                           networks=networks,\n",
    "                           optimizers=optimizers,\n",
    "                           density_estimator=density_estimator,\n",
    "                           train_Y_2=y2,\n",
    "                           ood_X=ood_x,\n",
    "                           ood_Y=ood_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pretrain_density_estimator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color='b', s=1, label='in domain data')\n",
    "plt.scatter(ood_x, ood_y, color='g', s=.5, label='ood data')\n",
    "plt.plot(x_test, density_estimator.score_samples(x_test))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "losses = {'a': [], 'e': [], 'f': []}\n",
    "\n",
    "for i in range(epochs):\n",
    "    new_losses = model.fit()\n",
    "    for key in 'afe':\n",
    "        losses[key].extend(new_losses[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses['f'], label='f_loss')\n",
    "plt.plot(losses['a'], label='a_loss')\n",
    "plt.plot(losses['e'], label='u_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = networks['f_predictor'](x_test).detach().numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "aleatoric_u = networks['a_predictor'](x_test).detach().numpy().ravel()\n",
    "a_low = predictions - np.sqrt(aleatoric_u)\n",
    "a_high = predictions + np.sqrt(aleatoric_u)\n",
    "\n",
    "plt.plot(x_test, y_test, '.', label='test_samples', alpha=.15)\n",
    "plt.plot(x_test, predictions, label='predictions', alpha=.3, lw=2)\n",
    "plt.fill_between(x_test.numpy().ravel(), a_low, a_high, alpha=.3, label='aleatoric')\n",
    "\n",
    "test_den = torch.FloatTensor(density_estimator.score_samples(x_test.numpy()).reshape(-1, 1))\n",
    "e_in = torch.cat((x_test.view(-1, 1), test_den), axis=1)\n",
    "epistemic_u = networks['e_predictor'](e_in).detach().numpy().ravel()\n",
    "\n",
    "e_low = predictions - np.sqrt(epistemic_u)\n",
    "e_high = predictions + np.sqrt(epistemic_u)\n",
    "\n",
    "plt.fill_between(x_test.numpy().ravel(), e_low, e_high, alpha=.3, label='epistemic')\n",
    "\n",
    "exp_epistemic_uncertainty = (networks['f_predictor'](x_test) - y_test).pow(2).detach().numpy().ravel()\n",
    "exp_total_uncertainty = exp_epistemic_uncertainty + 0.1 ** 2  # squaring noise to get variance !!\n",
    "\n",
    "exp_e_low = predictions - np.sqrt(exp_epistemic_uncertainty)\n",
    "exp_e_high = predictions + np.sqrt(exp_epistemic_uncertainty)\n",
    "\n",
    "plt.fill_between(x_test.numpy().ravel(), exp_e_low, exp_e_high, alpha=.15, label='out of sample error')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "total_uncertainty = epistemic_u + aleatoric_u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test, exp_total_uncertainty, label='true total uncertainty')\n",
    "plt.plot(x_test, total_uncertainty, label='predicted total uncertainty')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test.view(-1).numpy(), np.sqrt(exp_epistemic_uncertainty), label='true epistemic')\n",
    "plt.plot(x_test.view(-1).numpy(), np.sqrt(epistemic_u), label='predicted epistemic')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
